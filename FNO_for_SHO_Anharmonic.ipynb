{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch_harmonics neuraloperator"
      ],
      "metadata": {
        "id": "IHIXdVwvlRxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrGn0Y7kksrf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from neuralop.models import FNO  # Import FNO from NeuralOperator\n",
        "import scipy.sparse as sp\n",
        "import scipy.sparse.linalg as spla\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate\n",
        "from enum import Enum"
      ],
      "metadata": {
        "id": "Whgek4zolOLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerator = accelerate.Accelerator()\n",
        "device = accelerator.device"
      ],
      "metadata": {
        "id": "oKyAuMrxlsXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class PotentialType(Enum):\n",
        "#   Harmonic = 0\n",
        "#   Anharmonic = 1\n",
        "#   Well = 2"
      ],
      "metadata": {
        "id": "dq1jJvwyJlrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_potential_data(num_samples, grid_size, num_eigenvalues, device, lambda_value=0.1, dtype=torch.float32, potential_type: PotentialType = PotentialType.Anharmonic):\n",
        "#     # Create the grid and potential\n",
        "#     x = np.linspace(-5, 5, grid_size)\n",
        "#     y = np.linspace(-5, 5, grid_size)\n",
        "#     X, Y = np.meshgrid(x, y)\n",
        "\n",
        "#     match potential_type:\n",
        "#       case PotentialType.Well:\n",
        "#         raise NotImplementedError(\"Well potential not implemented yet\")\n",
        "#       case PotentialType.Anharmonic:\n",
        "#         V = 0.5 * (X**2 + Y**2) + lambda_value * (X**4 + Y**4) # Anharmonic potential\n",
        "#       case _:\n",
        "#         V = 0.5 * (X**2 + Y**2)  # Harmonic potential\n",
        "\n",
        "#     V_flat = V.flatten()  # Flatten once\n",
        "\n",
        "#     # Generate finite difference matrices for the potential grid\n",
        "#     dx = x[1] - x[0]\n",
        "#     D2_1D = sp.diags([1, -2, 1], [-1, 0, 1], shape=(grid_size, grid_size)) / dx**2\n",
        "#     I = sp.identity(grid_size)\n",
        "#     D2_2D = sp.kron(D2_1D, I) + sp.kron(I, D2_1D)\n",
        "\n",
        "#     # Precompute Hamiltonian\n",
        "#     H = -0.5 * D2_2D\n",
        "\n",
        "#     # Compute eigenvalues for all samples\n",
        "#     eigenvalues = []\n",
        "#     potentials = [V] * num_samples  # Create a list of the same potential for all samples\n",
        "\n",
        "#     for _ in range(num_samples):\n",
        "#         # Add the potential to the Hamiltonian\n",
        "#         H_with_potential = H + sp.diags(V_flat, 0)\n",
        "\n",
        "#         # Compute eigenvalues\n",
        "#         E, _ = spla.eigsh(H_with_potential, k=num_eigenvalues, which='SM')\n",
        "#         eigenvalues.append(np.sort(E))\n",
        "\n",
        "#     return torch.tensor(np.array(potentials), dtype=dtype).to(device), torch.tensor(np.array(eigenvalues), dtype=dtype).to(device)"
      ],
      "metadata": {
        "id": "uXFxXZb-lwli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PotentialType(Enum):\n",
        "    Harmonic = 1\n",
        "    Anharmonic = 2\n",
        "    Well = 3\n",
        "\n",
        "def generate_potential_data(\n",
        "    num_samples,\n",
        "    grid_size,\n",
        "    num_eigenvalues,\n",
        "    device,\n",
        "    lambda_value=0.1,\n",
        "    dtype=torch.float32,\n",
        "    potential_type: PotentialType = PotentialType.Anharmonic,\n",
        "    rotation_angle=0.0,  # Rotation angle in degrees\n",
        "    with_noise=False,\n",
        "    noise_std=0.01\n",
        "):\n",
        "    # Create the grid\n",
        "    x = np.linspace(-5, 5, grid_size)\n",
        "    y = np.linspace(-5, 5, grid_size)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "\n",
        "    # Rotate the grid\n",
        "    theta = np.radians(rotation_angle)  # Convert angle to radians\n",
        "    cos_theta, sin_theta = np.cos(theta), np.sin(theta)\n",
        "    X_rotated = cos_theta * X - sin_theta * Y\n",
        "    Y_rotated = sin_theta * X + cos_theta * Y\n",
        "\n",
        "    # Match the potential type\n",
        "    match potential_type:\n",
        "        case PotentialType.Well:\n",
        "            raise NotImplementedError(\"Well potential not implemented yet\")\n",
        "        case PotentialType.Anharmonic:\n",
        "            V = 0.5 * (X_rotated**2 + Y_rotated**2) + lambda_value * (X_rotated**4 + Y_rotated**4)  # Anharmonic potential\n",
        "        case _:\n",
        "            V = 0.5 * (X_rotated**2 + Y_rotated**2)  # Harmonic potential\n",
        "\n",
        "    V_flat = V.flatten()  # Flatten the potential grid\n",
        "\n",
        "    # Generate finite difference matrices for the potential grid\n",
        "    dx = x[1] - x[0]\n",
        "    D2_1D = sp.diags([1, -2, 1], [-1, 0, 1], shape=(grid_size, grid_size)) / dx**2\n",
        "    I = sp.identity(grid_size)\n",
        "    D2_2D = sp.kron(D2_1D, I) + sp.kron(I, D2_1D)\n",
        "\n",
        "    # Precompute Hamiltonian\n",
        "    H = -0.5 * D2_2D\n",
        "\n",
        "    # Compute eigenvalues for all samples\n",
        "    eigenvalues = []\n",
        "    potentials = [V] * num_samples  # Create a list of the same potential for all samples\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Add the potential to the Hamiltonian\n",
        "        H_with_potential = H + sp.diags(V_flat, 0)\n",
        "\n",
        "        # Compute eigenvalues\n",
        "        E, _ = spla.eigsh(H_with_potential, k=num_eigenvalues, which='SM')\n",
        "        eigenvalues.append(np.sort(E))\n",
        "\n",
        "    # check for noise flag\n",
        "    if with_noise:\n",
        "        for i in range(len(potentials)):\n",
        "            potentials[i] = potentials[i] + np.random.normal(0, noise_std, potentials[i].shape)\n",
        "            eigenvalues[i] = eigenvalues[i] + np.random.normal(0, noise_std, eigenvalues[i].shape)\n",
        "\n",
        "\n",
        "    return (\n",
        "        torch.tensor(np.array(potentials), dtype=dtype).to(device),\n",
        "        torch.tensor(np.array(eigenvalues), dtype=dtype).to(device),\n",
        "    )"
      ],
      "metadata": {
        "id": "rJ9j2n2Tr_G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_samples = 500\n",
        "grid_size = 30\n",
        "num_eigenvalues = 25\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 500\n",
        "\n",
        "# Initialize the model\n",
        "fno_model = FNO(\n",
        "    n_modes=(10, 10),\n",
        "    hidden_channels=64,\n",
        "    in_channels=1,\n",
        "    out_channels=num_eigenvalues,\n",
        "    lifting_channels=16,\n",
        "    projection_channels=16,\n",
        "    n_layers=64\n",
        ")\n",
        "\n",
        "config = {\n",
        "    \"num_samples\": num_samples,\n",
        "    \"grid_size\": grid_size,\n",
        "    \"num_eigenvalues\": num_eigenvalues,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"num_epochs\": num_epochs,\n",
        "    \"modes\": 10,\n",
        "    \"hidden_channels\": 64,\n",
        "    \"in_channels\": 1,\n",
        "    \"out_channels\": num_eigenvalues,\n",
        "    \"lifting_channels\": 32,\n",
        "    \"projection_channels\": 32,\n",
        "    \"training_batch\": 500,\n",
        "    \"validation_batch\": 10\n",
        "}\n",
        "\n",
        "\n",
        "# Create optimizer and loss function\n",
        "optimizer = optim.Adam(fno_model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "iK5rDKgUl2dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fno_model, optimizer, loss_fn, generate_potential_data = accelerator.prepare(fno_model, optimizer, loss_fn, generate_potential_data)"
      ],
      "metadata": {
        "id": "2xdscCKrmE7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_potentials, train_eigen_vals = generate_potential_data(num_samples, grid_size, num_eigenvalues, device=device, potential_type=PotentialType.Harmonic, with_noise=False)\n",
        "val_potentials, val_eigen_vals = generate_potential_data(10, grid_size, num_eigenvalues, device=device, potential_type=PotentialType.Anharmonic)"
      ],
      "metadata": {
        "id": "vR7EXdg2mUK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "vdGZ8gSRw2kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "# Training Loop\n",
        "losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to training mode\n",
        "    fno_model.train()\n",
        "\n",
        "    predicted_eigen_vals = fno_model(train_potentials.unsqueeze(1))\n",
        "\n",
        "    # Extract the eigenvalues by averaging over the spatial dimensions\n",
        "    predicted_eigen_vals = predicted_eigen_vals.mean(dim=[2, 3])  # Shape: [500, 25]\n",
        "\n",
        "    # Compute the loss\n",
        "    # train_eigen_vals = torch.tensor(train_eigen_vals, dtype=torch.float32).to(device)\n",
        "    loss = loss_fn(predicted_eigen_vals, train_eigen_vals)\n",
        "\n",
        "    # compute relative error\n",
        "    # loss = loss -  / torch.mean(train_eigen_vals)\n",
        "    losses.append(loss)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "    accelerator.backward(loss=loss)        # Compute gradients\n",
        "    optimizer.step()       # Update model parameters\n",
        "\n",
        "    # Print loss every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.8f}')\n",
        "\n",
        "end = time.time()\n",
        "print(f'Time taken: {end - start}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "jUFjqY79mbSU",
        "outputId": "8da01ae7-dfae-436a-c4f7-310db9426e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 27.06 MiB is free. Process 74279 has 14.72 GiB memory in use. Of the allocated memory 13.80 GiB is allocated by PyTorch, and 807.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5f1f059c6819>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfno_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredicted_eigen_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfno_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_potentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Extract the eigenvalues by averaging over the spatial dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neuralop/models/fno.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, output_shape, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfno_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain_padding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neuralop/layers/fno_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, index, output_shape)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_with_preactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_with_postactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_with_postactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neuralop/layers/fno_block.py\u001b[0m in \u001b[0;36mforward_with_postactivation\u001b[0;34m(self, x, index, output_shape)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mx_fno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;31m#self.convs(x, index, output_shape=output_shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neuralop/layers/spectral_convolution.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, output_shape)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mout_fft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfft_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 27.06 MiB is free. Process 74279 has 14.72 GiB memory in use. Of the allocated memory 13.80 GiB is allocated by PyTorch, and 807.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Phase\n",
        "fno_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Forward pass: compute predicted eigenvalues for validation data\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    predicted_val_eigen_vals = fno_model(val_potentials.unsqueeze(1))\n",
        "    predicted_val_eigen_vals = predicted_val_eigen_vals.mean(dim=[2, 3])  # Shape: [10, 25]\n",
        "\n",
        "# Compute validation loss\n",
        "# val_eigen_vals = torch.tensor(val_eigen_vals, dtype=torch.float32).to(device)\n",
        "val_loss = loss_fn(predicted_val_eigen_vals, val_eigen_vals)\n",
        "\n",
        "# Print validation loss\n",
        "print(f'Validation Loss: {val_loss.item():.5f}')\n",
        "\n",
        "# Optional: Calculate additional metrics\n",
        "# For example, Mean Absolute Error (MAE)\n",
        "mae = torch.mean(torch.abs(predicted_val_eigen_vals - val_eigen_vals))\n",
        "print(f'Mean Absolute Error: {mae.item():.5f}')\n",
        "\n",
        "\n",
        "\n",
        "# Plotting the first predicted vs actual eigenvalues\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(predicted_val_eigen_vals[0].cpu(), label='Predicted Eigenvalues', marker='o')\n",
        "plt.plot(val_eigen_vals[0].cpu(), label='True Eigenvalues', marker='x')\n",
        "plt.title('Predicted vs True Eigenvalues for First Validation Sample')\n",
        "plt.xlabel('Eigenvalue Index')\n",
        "plt.ylabel('Eigenvalue')\n",
        "plt.legend()\n",
        "plt.savefig('validation_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YxQImpRSoLEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt_losses = [i.item() for i in losses]\n",
        "plt.plot(plt_losses)\n",
        "plt.hlines(plt_losses[-1], 0, len(plt_losses), linestyles='dashed', color='r', label=f'final loss ({round(plt_losses[-1], 5)})')\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Square Error')\n",
        "plt.title('Training Loss across Training Epochs')\n",
        "plt.legend()\n",
        "plt.savefig('training_loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OYjYLslKttgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt_losses = [i.item() for i in losses]\n",
        "plt.plot(plt_losses)\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Log Error')\n",
        "plt.yscale('log')\n",
        "plt.title('Training Loss on Log Scale')\n",
        "plt.legend()\n",
        "plt.savefig('log_training_loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tt03WxKi_JoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "Q4LpYxvcAXVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('losses.pkl', 'wb') as f:\n",
        "    pickle.dump(losses, f)"
      ],
      "metadata": {
        "id": "XQWLMlReAdPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"train\": {\"potentials\": train_potentials, \"eigenvalues\": train_eigen_vals},\n",
        "    \"validate\": {\"potentials\": val_potentials, \"eigenvalues\": val_eigen_vals}\n",
        "}\n",
        "\n",
        "with open('data.pkl', 'wb') as f:\n",
        "    pickle.dump(data, f)"
      ],
      "metadata": {
        "id": "7JkxYRFzAlkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"config.pkl\", \"wb\") as f:\n",
        "    pickle.dump(config, f)"
      ],
      "metadata": {
        "id": "vavmW17RQrTf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}